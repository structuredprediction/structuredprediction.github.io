---
layout: page22
title: Schedule
permalink: /SPNLP22/schedule/
name: 3
---

## Invited Speakers

-   Angela Fan, Facebook AI Research and LORIA, France
-   Wilker Aziz, ILLC, University of Amsterdam, Netherlands
-   Sebastian Riedel, Meta AI and University College London, United Kingdom
-   Siva Reddy, Facebook CIFAR AI and Mila, McGill University, Canada
-   Albert Gu, Stanford University

## Schedule: May 27th, 2022 [Timezone: GMT]

<div class="scheduletable" markdown="block">
  
|_Time_| _Event_|
|-----:|-------|
|  9:00&nbsp;AM | **Opening Remarks** |
|  9:10&nbsp;AM | **Invited Talk** <br/>Can we learn more explicit relationships between languages in multilingual machine translation?<br/>**Angela Fan** (Facebook AI Research, France) |
|  9:50&nbsp;AM | **Invited Talk** <br/>Decoding is deciding under uncertainty — the case of NMT.<br/>**Wilker Aziz** (ILLC, University of Amsterdam, Netherlands) |
| 10:30&nbsp;AM | **Break** |
| 11:00&nbsp;PM | **Contributed Talk**<br/>Neural String Edit Distance<br/>Jindřich Libovický and Alexander Fraser|
| 11:15&nbsp;PM | **Contributed Talk**<br/>A Joint Learning Approach for Semi-supervised Neural Topic Modeling<br/>Jeffrey Chiu, Rajat Mittal, Neehal Tumma, Abhishek Sharma and Finale Doshi-Velez|
| 11:30&nbsp;PM | **Contributed Talk**<br/>Predicting Attention Sparsity in Transformers<br/>Marcos Vinicius Treviso, António Góis, Patrick Fernandes, Erick Rocha Fonseca, and Andre Martins|
| 11:45&nbsp;AM | **Online Poster Session**<br/><br/>Joint Entity and Relation Extraction Based on Table Labeling Using Convolutional Neural Networks.<br/>Youmi Ma, Tatsuya Hiraoka and Naoaki Okazaki<br/><br/>Multilingual Syntax-aware Language Modeling through Dependency Tree Conversion<br/>Shunsuke Kando, Hiroshi Noji and Yusuke Miyao<br/><br/>DomiKnowS: A Library for Integration of Symbolic Domain Knowledge in Deep Learning.<br/>Hossein Rajaby Faghihi, Quan Guo, Andrzej Uszok, Aliakbar Nafar and Parisa Kordjamshidi<br/><br/>Diverse Text Generation via Variational Encoder-Decoder Models with Gaussian Process Priors.<br/>Wanyu Du, Jianqiao Zhao, Liwei Wang and Yangfeng Ji<br/><br/>Query and Extract: Refining Event Extraction as Type-oriented Binary Decoding.<br/>Sijia Wang, Mo Yu, Shiyu Chang, Lichao Sun and Lifu Huang<br/><br/>Extracting Temporal Event Relation with Syntax-guided Graph Transformer.<br/>Shuaicheng Zhang, Qiang Ning and Lifu Huang|
| 12:30&nbsp;PM | **Lunch break** |
| 14:00&nbsp;PM | **Invited Talk**<br/><br/>**Sebastian Riedel** (Meta AI and University College London, United Kingdom) |
| 14:45&nbsp;AM | **In-person Poster Session**<br/><br/>A Joint Learning Approach for Semi-supervised Neural Topic Modeling.<br/>Jeffrey Chiu, Rajat Mittal, Neehal Tumma, Abhishek Sharma and Finale Doshi-Velez<br/><br/>SlotGAN: Detecting Mentions in Text via Adversarial Distant Learning<br/>Daniel Daza, Michael Cochez and Paul Groth<br/><br/>TempCaps: A Capsule Network-based Embedding Model for Temporal Knowledge Graph Completion.<br/>Guirong Fu, Zhao Meng, Zhen Han, Zifeng Ding, Yunpu Ma, Matthias Schubert, Volker Tresp and Roger Wattenhofer<br/><br/>Predicting Attention Sparsity in Transformers<br/>Marcos Vinicius Treviso, António Góis, Patrick Fernandes, Erick Rocha Fonseca, and Andre Martins<br/><br/>Neural String Edit Distance<br/>Jindřich Libovický and Alexander Fraser<br/><br/>Conditioning Pretrained Language Models with Multi-Modal information on Data-to-Text Generation.<br/>Qianqian Qi, Zhenyun Deng, Yonghua Zhu, Lia Lee, Jiamou Liu and Michael J. Witbrock<br/><br/>Language Modelling via Learning to Rank.<br/>Arvid Frydenlund, Gagandeep Singh and Frank Rudzicz|
| 15:00&nbsp;AM | **Break** |
| 15:30&nbsp;PM | **Invited Talk**<br/>Do we still need inductive biases after Transformer language models?<br/>**Siva Reddy** (Facebook CIFAR AI and Mila, McGill University, Canada) |
| 16:15&nbsp;PM | **Invited Talk**<br/>Efficiently Modeling Long Sequences with Structured State Spaces.<br/>**Albert Gu** (Stanford University) |
| 17:00&nbsp;PM | **Closing Remarks**  |

</div>



